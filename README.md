# üöÄ Extracci√≥n Modular de Reportes Mineros (NI 43-101)

Este proyecto implementa un pipeline de ingenier√≠a de datos dise√±ado para la extracci√≥n estructurada, validaci√≥n y normalizaci√≥n de informaci√≥n t√©cnica desde reportes mineros en formato PDF (NI 43-101). Utiliza Modelos de Lenguaje Grande (LLMs) orquestados mediante LlamaIndex para transformar datos no estructurados en esquemas JSON rigurosamente tipados.

## üìã Tabla de Contenidos
- [Arquitectura y Funcionamiento](#arquitectura-y-funcionamiento)
- [Instalaci√≥n y Uso](#instalaci√≥n-y-uso)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Stack Tecnol√≥gico](#stack-tecnol√≥gico)
- [Costos Operativos](#costos-operativos)
- [Desaf√≠os y Limitaciones](#desaf√≠os-y-limitaciones)
- [Propuesta de Escalabilidad (Producci√≥n)](#propuesta-de-escalabilidad-producci√≥n)

## üèó Arquitectura y Funcionamiento

El sistema opera bajo un enfoque modular de "Divide y Vencer√°s", procesando el documento en cuatro etapas secuenciales para maximizar la precisi√≥n y mitigar las limitaciones de ventana de contexto de los LLMs.

1.  **Ingesta Inteligente**: Escaneo preliminar del PDF para mapear √≠ndices, tablas y secciones clave.
2.  **Extracci√≥n Modular**:
    *   **Metadata**: Identificaci√≥n de proyecto, ubicaci√≥n y propietarios.
    *   **Recursos Minerales**: Extracci√≥n de tablas de recursos, leyes de corte y estad√≠sticas de sondajes.
    *   **Reservas Minerales**: Identificaci√≥n de reservas probadas/probables y metalurgia.
    *   **Econom√≠a**: An√°lisis de CAPEX, OPEX, NPV e IRR.
3.  **Validaci√≥n Cruzada**: Verificaci√≥n l√≥gica de datos (ej. Reservas < Recursos) y normalizaci√≥n de unidades.
4.  **Persistencia**: Generaci√≥n de reportes JSON y logs de validaci√≥n.

## üíª Instalaci√≥n y Uso

### Prerrequisitos
*   Linux/MacOS (Probado en Ubuntu 22.04)
*   Python 3.10+
*   Clave de API de OpenAI

### Ejecuci√≥n
1.  **Configurar entorno**:
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

2.  **Variables de Entorno**:
    Crear un archivo `.env` en la ra√≠z:
    ```env
    OPENAI_API_KEY=sk-proj-xxxx
    ```

3.  **Ejecutar Pipeline**:
    Coloque los archivos PDF en la carpeta `data/` y ejecute:
    ```bash
    python main.py
    ```
    Los reportes se generar√°n en la carpeta `output/`.

## üìÇ Estructura del Proyecto

```text
.
‚îú‚îÄ‚îÄ data/                  # Directorio de entrada (PDFs)
‚îú‚îÄ‚îÄ output/                # Directorio de salida (JSONs)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ processor.py       # L√≥gica core de extracci√≥n y procesamiento (LlamaIndex)
‚îÇ   ‚îú‚îÄ‚îÄ models.py          # Definiciones de esquemas Pydantic
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Utilidades de I/O y normalizaci√≥n
‚îú‚îÄ‚îÄ main.py                # Entrypoint y orquestador del batch processing
‚îî‚îÄ‚îÄ requirements.txt       # Dependencias del proyecto
```

## üõ† Stack Tecnol√≥gico

La elecci√≥n del stack prioriza la **precisi√≥n sem√°ntica** sobre la velocidad pura, dado la naturaleza cr√≠tica de los datos financieros mineros.

*   **LlamaIndex**: Framework de orquestaci√≥n para RAG (Retrieval-Augmented Generation). Seleccionado por su capacidad superior para manejar contextos largos y estructuras de documentos complejos comparado con LangChain crudo.
*   **OpenAI GPT-4o-mini**: Motor de inferencia.
    *   *Por qu√©*: Ofrece un balance √≥ptimo entre capacidad de razonamiento y costo-eficiencia para tareas de extracci√≥n estructurada.
*   **Pydantic**: Validaci√≥n de datos y definici√≥n de contratos de interfaz. Asegura que el JSON de salida cumpla estrictamente con el esquema esperado.

## üí∞ Costos Operativos

El modelo subyacente es **gpt-4o-mini**. La estimaci√≥n de costos basada en el pricing actual es:

| Concepto | Precio / 1M Tokens |
| :--- | :--- |
| **Input (Entrada)** | $0.150 |
| **Cached Input** | $0.075 |
| **Output (Salida)** | $0.600 |

*Nota: Un reporte NI 43-101 t√≠pico consume entre 15k y 40k tokens dependiendo de la densidad tablas.*

## üöß Desaf√≠os y Limitaciones

### Desaf√≠os Encontrados
1.  **Heterogeneidad de Documentos**: Los reportes no siguen un est√°ndar visual √∫nico; tablas de recursos pueden ser im√°genes, texto mal formateado o tablas nativas.
2.  **Alucinaci√≥n en Celdas Vac√≠as**: Los LLMs tienden a "inferir" valores nulos (0 vs null). Se implementaron validadores en `models.py` para mitigar esto.
3.  **Hardware Limitado**: La extracci√≥n de PDF (OCR + Parsing) es intensiva en CPU.
4.  **Tiempo de Ejecuci√≥n**: El procesamiento secuencial de secciones grandes es lento (1-3 min por archivo).

### Limitaciones Actuales
*   **OCR**: Actualmente depende de la capa de texto del PDF. PDFs escaneados (im√°genes) requieren integraci√≥n con Tesseract o Azure Document Intelligence.
*   **Tablas Complejas**: Tablas anidadas o con headers verticales rotados pueden perder alineaci√≥n en la extracci√≥n de texto plano.

### Alternativas Consideradas (Mejoras Potenciales)
*   **MinerU / Marker**: Herramientas especializadas en conversi√≥n de PDF a Markdown que superan a `PyMuPDF` en layout analysis, pero requieren GPU para inferencia eficiente.
*   **Unstructured.io**: Potente para ingesta, pero costoso en versi√≥n cloud o complejo de desplegar on-premise.

## üöÄ Propuesta de Escalabilidad (Producci√≥n) - Arquitectura AWS

Para llevar esta soluci√≥n a un nivel productivo y procesar miles de documentos (10,000+), proponemos una arquitectura **Serverless / Event-Driven** totalmente nativa en AWS para optimizar costos y reducir la carga operativa.

### Diagrama de Flujo

1.  **Ingesta (S3 + SQS)**:
    *   Los PDFs se cargan en **Amazon S3** (`raw-bucket`).
    *   S3 Event Notifications env√≠an mensajes a una cola **Amazon SQS**, desacoplando la ingesta del procesamiento.

2.  **C√≥mputo (AWS Batch / Lambda)**:
    *   **Paso 1 (GPU - AWS Batch)**: Se utiliza **AWS Batch** con instancias EC2 GPU (ej. g4dn) para ejecutar trabajos pesados de conversi√≥n PDF a Markdown (usando herramientas como MinerU o Marker) de manera ef√≠mera.
    *   **Paso 2 (Orquestaci√≥n - AWS Lambda)**: Funciones Lambda consumen los Markdowns limpios y ejecutan la l√≥gica de `LlamaIndex`.
        *   *Integraci√≥n LLM*: La Lambda invoca a la API de OpenAI (o **Amazon Bedrock** si se desea seguridad privada total).

3.  **Almacenamiento y Consultas**:
    *   **Amazon DynamoDB**: Almacenamiento NoSQL para los JSONs resultantes (baja latencia y esquema flexible).
    *   **Amazon S3 (Results)**: Archivo de backups de los JSONs generados.
    *   **Amazon Athena**: Para realizar consultas SQL anal√≠ticas directamente sobre los resultados en S3 sin necesidad de cargar un Data Warehouse complejo.

4.  **Observabilidad y Monitoreo**:
    *   **Amazon CloudWatch**: Centralizaci√≥n de logs de aplicaci√≥n y m√©tricas de infraestructura.
    *   **AWS X-Ray**: Trazabilidad distribuida para detectar cuellos de botella entre servicios.


![Arquitectura AWS](flujo_datos.drawio.svg)

---
*Desarrollado para el Test T√©cnico de Data Engineer - 2026*
